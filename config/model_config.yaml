
llama3.1-8b:
  hf_key: "meta-llama/Meta-Llama-3.1-8B-Instruct"
  question_start_tag: "<|start_header_id|>user<|end_header_id|>\n\n"
  question_end_tag: "<|eot_id|>"
  answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  retain_answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  answer_end_tag: "<|eot_id|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  t440_config: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/retain_and_test_retain_llama3.1-8b_B32_G4_E5_lr2e-5_ComprehensiveQA/t440_config.json"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama3.1-8b_B32_G4_E5_lr2e-5_ComprehensiveQA"

qwen2.5-7b:
  hf_key: "Qwen/Qwen2.5-7B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_qwen2.5-7b_B32_G4_E5_lr2e-5_ComprehensiveQA_PadToken"


qwen2.5-1.5b:
  hf_key: "Qwen/Qwen2.5-1.5B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  #pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_qwen2.5-1.5b_B16_G8_E5_lr2e-5_ComprehensiveQA_PadToken"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_qwen2.5-1.5b_B64_G2_E8_lr2e-5_ComprehensiveQA"

  
qwen2.5-14b:
  hf_key: "Qwen/Qwen2.5-14B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  pii_target_model_path: "save_model/PII/full_with_qa_qwen2.5-14b_B4_G1_E3_lr1e-5/checkpoint-15846"

qwen2.5-3b:
  hf_key: "Qwen/Qwen2.5-3B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  pii_target_model_path: "save_model/PII/full_with_qa_qwen2.5-3b_B64_G2_E7_lr2e-5_ComprehensiveQA"


qwen2.5-32b:
  hf_key: "Qwen/Qwen2.5-32B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_qwen2.5-32b_B2_G1_E2_lr1e-5/checkpoint-10564"

llama2-7b:
  hf_key: "NousResearch/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  answer_end_tag: ""
  retain_answer_tag: "" 
  flash_attention2: "false"
  gradient_checkpointing: "true"
  # this model will be used for unlearning by default
  pii_target_model_path: "save_model/PII/full_with_qa_llama2-7b_B32_G4_E5_lr2e-5_ComprehensiveQA"

llama2-7b_ansspace:
  hf_key: "NousResearch/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: " " ## NEED TO ADD A SPACE TO NOT TOKENIZE SUBJECT FROM ANS TOGETHER WITH THE [/INST] TAG
  retain_answer_tag: ""
  answer_end_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "true"
  # this model will be used for unlearning by default
  pii_target_model_path: "save_model/PII/full_with_qa_llama2-7b_B32_G4_E5_lr2e-5_ComprehensiveQA"

llama2-13b:
  hf_key: "meta-llama/Llama-2-13b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: "" ## NEED TO ADD A SPACE TO NOT TOKENIZE SUBJECT FROM ANS TOGETHER WITH THE [/INST] TAG
  answer_end_tag: ""
  retain_answer_tag: "" 
  flash_attention2: "false"
  gradient_checkpointing: "true"
  pii_target_model_path: "save_model/PII/full_with_qa_llama2-13b_B16_G4_E5_lr2e-5_ComprehensiveQA/checkpoint-1650"


phi3-5-mini-instruct:
  hf_key: "microsoft/Phi-3.5-mini-instruct"
  question_start_tag: "<|user|>\n"
  question_end_tag: "<|end|>\n"
  
  question_start_tag_inference: "<|user|> "
  question_end_tag_inference: "<|end|>"
  answer_start_tag_inference: "<|assistant|>"
  answer_end_tag_inference: "<|end|>"

  answer_tag: "<|assistant|>\n"
  retain_answer_tag: "<|assistant|>\n"
  answer_end_tag: "<|end|>\n"
  flash_attention2: "false"
  gradient_checkpointing: "true"
  pii_target_model_path: "save_model/PII/full_with_qa_phi3-5-mini-instruct_B32_G4_E5_lr2e-5_ComprehensiveQA"
  harry_target_model_path: "Maybe1407/harry_phi_to_unlearn"
  zsre_target_model_path: "Maybe1407/zsre_phi_to_unlearn"

phi:
  hf_key: "microsoft/phi-1_5"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  retain_answer_tag: "Answer: "
  answer_end_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "false"
  tofu_target_model_path: "save_model/TOFU/full_phi_TOFU_B8_G2_E5_lr1e-4/checkpoint-1250"
  harry_target_model_path: "Maybe1407/harry_phi_to_unlearn"
  zsre_target_model_path: "Maybe1407/zsre_phi_to_unlearn"

phi_chat:
  hf_key: "rasyosef/Phi-1_5-Instruct-v0.1"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>\n"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"

  flash_attention2: "false"
  gradient_checkpointing: "true"
  tofu_target_model_path: "save_model/TOFU/full_phi_chat_B8_G4_E5_lr5e-5/checkpoint-625"
  harry_target_model_path: "Maybe1407/harry_phi_to_unlearn"
  zsre_target_model_path: "Maybe1407/zsre_phi_to_unlearn"
  pii_target_model_path: "save_model/PII/full_with_qa_phi_chat_B32_G4_E5_lr2e-5_ComprehensiveQA"