llama3-8b:
  hf_key: "meta-llama/Meta-Llama-3-8B-Instruct"
  question_start_tag: "<|start_header_id|>user<|end_header_id|>\n\n"
  question_end_tag: "<|eot_id|>"
  answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  retain_answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  answer_end_tag: "<|eot_id|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"

  # this model will be used for unlearning by default
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama3-8b_B32_G4_E5_lr2e-5_ComprehensiveQA"



llama3.1-8b:
  hf_key: "meta-llama/Meta-Llama-3.1-8B-Instruct"
  question_start_tag: "<|start_header_id|>user<|end_header_id|>\n\n"
  question_end_tag: "<|eot_id|>"
  answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  retain_answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  answer_end_tag: "<|eot_id|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"

  # this model will be used for unlearning by default
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama3.1-8b_B32_G4_E5_lr2e-5_ComprehensiveQA/checkpoint-1650"


qwen2.5-7b:
  hf_key: "Qwen/Qwen2.5-7B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"

  question_start_tag_inference: "<|im_start|>user "
  question_end_tag_inference: "<|im_end|>"
  answer_start_tag_inference: "<|im_start|>assistant|> "
  answer_end_tag_inference: "<|im_end|>"


  flash_attention2: "true"
  gradient_checkpointing: "true"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_qwen2.5-7b_B32_G4_E5_lr2e-5_ComprehensiveQA/checkpoint-1650"


qwen2.5-32b:
  hf_key: "Qwen/Qwen2.5-32B-Instruct"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"




llama3.1-70b:
  hf_key: "meta-llama/Llama-3.1-70B-Instruct"
  question_start_tag: "<|start_header_id|>user<|end_header_id|>\n\n"
  question_end_tag: "<|eot_id|>"
  answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  retain_answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"

  answer_end_tag: "<|eot_id|>"
  flash_attention2: "true"
  gradient_checkpointing: "true"

  # this model will be used for unlearning by default
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama3-8b_B32_G4_E5_lr2e-5_ComprehensiveQA"
  #pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII_old/full_llama2-7b_B8_G4_E10_lr1e-5/checkpoint-393"


llama2-7b:
  hf_key: "NousResearch/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: "" ## NEED TO ADD A SPACE TO NOT TOKENIZE SUBJECT FROM ANS TOGETHER WITH THE [/INST] TAG
  answer_end_tag: ""
  retain_answer_tag: "" 
  flash_attention2: "false"
  gradient_checkpointing: "true"
  # this model will be used for unlearning by default
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama2-7b_B32_G4_E5_lr2e-5_ComprehensiveQA"


llama2-13b:
  hf_key: "meta-llama/Llama-2-13b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: "" ## NEED TO ADD A SPACE TO NOT TOKENIZE SUBJECT FROM ANS TOGETHER WITH THE [/INST] TAG
  answer_end_tag: ""
  retain_answer_tag: "" 
  flash_attention2: "false"
  gradient_checkpointing: "true"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama2-13b_B16_G4_E5_lr2e-5_ComprehensiveQA/checkpoint-1650"

llama2-7b_ansspace:
  hf_key: "NousResearch/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: " " ## NEED TO ADD A SPACE TO NOT TOKENIZE SUBJECT FROM ANS TOGETHER WITH THE [/INST] TAG
  retain_answer_tag: ""
  answer_end_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "true"
  # this model will be used for unlearning by default
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_llama2-7b_B32_G4_E5_lr2e-5_ComprehensiveQA"




phi3-5-mini-instruct:
  hf_key: "microsoft/Phi-3.5-mini-instruct"
  question_start_tag: "<|user|>\n"
  question_end_tag: "<|end|>\n"
  
  question_start_tag_inference: "<|user|> "
  question_end_tag_inference: "<|end|>"
  answer_start_tag_inference: "<|assistant|>"
  answer_end_tag_inference: "<|end|>"

  answer_tag: "<|assistant|>\n"
  retain_answer_tag: "<|assistant|>\n"
  answer_end_tag: "<|end|>\n"
  flash_attention2: "false"
  gradient_checkpointing: "true"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_phi3-5-mini-instruct_B32_G4_E5_lr2e-5_ComprehensiveQA"
  harry_target_model_path: "Maybe1407/harry_phi_to_unlearn"
  zsre_target_model_path: "Maybe1407/zsre_phi_to_unlearn"

phi:
  hf_key: "microsoft/phi-1_5"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  retain_answer_tag: "Answer: "
  answer_end_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "false"
  # tofu_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/TOFU/full_phi_B8_G2_E5_lr1e-4_use_piiFalse/checkpoint-1250"
  tofu_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/TOFU/full_phi_TOFU_B8_G2_E5_lr1e-4/checkpoint-1250"
  harry_target_model_path: "Maybe1407/harry_phi_to_unlearn"
  zsre_target_model_path: "Maybe1407/zsre_phi_to_unlearn"

phi_chat:
  hf_key: "rasyosef/Phi-1_5-Instruct-v0.1"
  question_start_tag: "<|im_start|>user\n"
  question_end_tag: "<|im_end|>\n"
  answer_tag: "<|im_start|>assistant\n"
  retain_answer_tag: "<|im_start|>assistant\n"
  answer_end_tag: "<|im_end|>"

  flash_attention2: "false"
  gradient_checkpointing: "true"
  # pii_target_model_path: 
  tofu_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/TOFU/full_phi_chat_B8_G4_E5_lr5e-5/checkpoint-625"
  harry_target_model_path: "Maybe1407/harry_phi_to_unlearn"
  zsre_target_model_path: "Maybe1407/zsre_phi_to_unlearn"
  pii_target_model_path: "/projects/0/hpmlprjs/LLM/danp/UGBench/save_model/PII/full_with_qa_phi_chat_B32_G4_E5_lr2e-5_ComprehensiveQA"